{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_fasta(fasta_file):\n",
    "    lines = fasta_file.readlines()\n",
    "    body = \"\"\n",
    "    for l in lines:\n",
    "        if l[0] == \">\":\n",
    "            if body != \"\":\n",
    "                yield name.strip('\\n'), body.strip('\\n')            \n",
    "            name = l[1:]\n",
    "            body = \"\"\n",
    "        else:\n",
    "            body += l.strip('\\n')\n",
    "    yield name.strip('\\n'), body.strip('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/yeast.fasta', 'r') as ff:\n",
    "    yeast_dset = {}\n",
    "    for name, seq in read_fasta(ff):\n",
    "        yeast_dset[name] = seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MYYIMFLYNMLLIIILIFYSIVGVPIIIFNNNYYWDPDIFLFIIYYFIKFIIIFNLYLYYMINYIVYTPSGSPPGRGTYILLYNMLYSYNMFIDYVMKFITCVTYMYLMFWLLSPTPSPYYVSEVPVS'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yeast_dset['Q9ZZX9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/human.fasta', 'r') as ff:\n",
    "    human_dset = {}\n",
    "    for name, seq in read_fasta(ff):\n",
    "        if 'U' in seq or 'X' in seq:\n",
    "            if name == \"P80667\":\n",
    "                print(seq)\n",
    "            continue\n",
    "        human_dset[name] = seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'P04786'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-9fd7d62b7ee5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhuman_dset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'P04786'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'P04786'"
     ]
    }
   ],
   "source": [
    "human_dset['P04786']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/human_ct/ignore.txt\", \"w+\") as fff:\n",
    "    with open('data/human.fasta', 'r') as ff:\n",
    "        for name, seq in read_fasta(ff):\n",
    "            if 'U' in seq or 'X' in seq:\n",
    "                fff.write(\"{}\\n\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_splits_file(sp_file, label):\n",
    "    data = []\n",
    "    with open(sp_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            if label == 'neg':\n",
    "                x,y = l.split(\" \")\n",
    "            else:\n",
    "                x,y,_ = l.split(\" \")\n",
    "            if x == \"P04786\" or y == \"P04786\":\n",
    "                import pdb; pdb.set_trace()\n",
    "                print(\"heelo\")\n",
    "            data.append((x.strip('\\n'), y.strip('\\n'), label))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-90-e35f5b9d3b4e>(12)parse_splits_file()\n",
      "-> print(\"heelo\")\n",
      "(Pdb) !sp_file\n",
      "'data/negativeSimTest/nonRed/C1/yeastCV/split_0/0.train.pos'\n",
      "(Pdb) exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-6a30467c94ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_splits_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/negativeSimTest/nonRed/{}/yeastCV/split_0/{}.{}.pos'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mneg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_splits_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/negativeSimTest/nonRed/{}/yeastCV/split_0/{}.{}.neg'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mpos_test_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_test_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-90-e35f5b9d3b4e>\u001b[0m in \u001b[0;36mparse_splits_file\u001b[0;34m(sp_file, label)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P04786\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P04786\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"heelo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-90-e35f5b9d3b4e>\u001b[0m in \u001b[0;36mparse_splits_file\u001b[0;34m(sp_file, label)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P04786\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P04786\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"heelo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemami/anaconda3/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemami/anaconda3/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "diff = [\"C1\", \"C2\", \"C3\"]\n",
    "mode = [\"train\", \"train\", \"test\"]\n",
    "splits = 10\n",
    "pos_test_samples = [set(), set(), set()]\n",
    "neg_test_samples = [set(), set(), set()]\n",
    "for i in range(3):\n",
    "    for j in range(splits):\n",
    "        pos = parse_splits_file('data/negativeSimTest/nonRed/{}/yeastCV/split_0/{}.{}.pos'.format(diff[i], j, mode[i]), 'pos')\n",
    "        neg = parse_splits_file('data/negativeSimTest/nonRed/{}/yeastCV/split_0/{}.{}.neg'.format(diff[i], j, mode[i]), 'neg')\n",
    "        pos_test_samples[i] = pos_test_samples[i].union(set(pos))\n",
    "        neg_test_samples[i] = neg_test_samples[i].union(set(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 758 518 1276\n",
      "0.0 758 515 1273\n",
      "0.0 758 527 1285\n",
      "0.0 758 517 1275\n",
      "0.0 757 523 1280\n",
      "0.0 758 520 1278\n",
      "0.0 758 504 1262\n",
      "0.0 758 511 1269\n",
      "0.0 758 513 1271\n"
     ]
    }
   ],
   "source": [
    "splits = 10\n",
    "for j in range(splits-1):\n",
    "    pos = parse_splits_file('data/negativeSimTest/nonRed/C1/humanCV/split_0/{}.train.pos'.format(j), 'pos')\n",
    "    neg = parse_splits_file('data/negativeSimTest/nonRed/C2/humanCV/split_0/{}.test.pos'.format(j), 'pos')\n",
    "    pos = set(pos)\n",
    "    neg = set(neg)\n",
    "    print(len(pos.intersection(neg))/len(pos.union(neg)), len(pos), len(neg), len(pos.union(neg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* pos test overlap btwn C1 and C2: 0.1828612405880244\n",
      "* neg test overlap btwn C1 and C2: 0.00020738282870178348\n",
      "* pos test overlap btwn C1 and C3: 0.0\n",
      "* neg test overlap btwn C1 and C3: 0.0\n",
      "* pos test overlap btwn C2 and C3: 0.0\n",
      "* neg test overlap btwn C2 and C3: 2.1546616103940875e-05\n",
      "\n",
      " pos test size for C1: 1636\n",
      " neg test size for C1: 33393\n",
      " pos test size for C2: 1663\n",
      " neg test size for C2: 38952\n",
      " pos test size for C3: 746\n",
      " neg test size for C3: 7460\n"
     ]
    }
   ],
   "source": [
    "# C1 - C2\n",
    "c1_c2_int = len(pos_test_samples[0].intersection(pos_test_samples[1]))\n",
    "total = len(pos_test_samples[0].union(pos_test_samples[1]))\n",
    "print(\"* pos test overlap btwn C1 and C2: {}\".format(c1_c2_int/total))\n",
    "c1_c2_int = len(neg_test_samples[0].intersection(neg_test_samples[1]))\n",
    "total = len(neg_test_samples[0].union(neg_test_samples[1]))\n",
    "print(\"* neg test overlap btwn C1 and C2: {}\".format(c1_c2_int/total))\n",
    "# C1 - C3\n",
    "c1_c3_int = len(pos_test_samples[0].intersection(pos_test_samples[2]))\n",
    "total = len(pos_test_samples[0].union(pos_test_samples[2]))\n",
    "print(\"* pos test overlap btwn C1 and C3: {}\".format(c1_c3_int/total))\n",
    "c1_c3_int = len(neg_test_samples[0].intersection(neg_test_samples[2]))\n",
    "total = len(neg_test_samples[0].union(neg_test_samples[2]))\n",
    "print(\"* neg test overlap btwn C1 and C3: {}\".format(c1_c3_int/total))\n",
    "# C2 - C3\n",
    "c2_c3_int = len(pos_test_samples[1].intersection(pos_test_samples[2]))\n",
    "total = len(pos_test_samples[1].union(pos_test_samples[2]))\n",
    "print(\"* pos test overlap btwn C2 and C3: {}\".format(c2_c3_int/total))\n",
    "c2_c3_int = len(neg_test_samples[1].intersection(neg_test_samples[2]))\n",
    "total = len(neg_test_samples[1].union(neg_test_samples[2]))\n",
    "print(\"* neg test overlap btwn C2 and C3: {}\".format(c2_c3_int/total))\n",
    "\n",
    "print()\n",
    "for i in range(3):\n",
    "    print(\" pos test size for C{}: {}\".format(i+1, len(pos_test_samples[i])))\n",
    "    print(\" neg test size for C{}: {}\".format(i+1, len(neg_test_samples[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yeast \n",
    "* pos test overlap btwn C1 and C2: 0.1828612405880244\n",
    "* neg test overlap btwn C1 and C2: 0.00020738282870178348\n",
    "* pos test overlap btwn C1 and C3: 0.0\n",
    "* neg test overlap btwn C1 and C3: 0.0\n",
    "* pos test overlap btwn C2 and C3: 0.0\n",
    "* neg test overlap btwn C2 and C3: 2.1546616103940875e-05\n",
    "\n",
    "## Human\n",
    "* pos test overlap btwn C1 and C2: 0.13919952913478517\n",
    "* neg test overlap btwn C1 and C2: 1.1159344276930287e-05\n",
    "* pos test overlap btwn C1 and C3: 0.0\n",
    "* neg test overlap btwn C1 and C3: 0.0\n",
    "* pos test overlap btwn C2 and C3: 0.0\n",
    "* neg test overlap btwn C2 and C3: 0.0\n",
    "\n",
    "100% overlap between C1/C2 train and C3 test for positive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P21524'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_i[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocovariance featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.52927114e-01 -1.00003333e-01 -9.02148736e-03 -3.27183495e-02\n",
      "  -1.43409980e+01 -3.15187416e+00 -2.82959477e-02]\n",
      " [ 3.05401392e-01 -2.33341111e-01 -9.08854103e-03 -4.10797055e-01\n",
      "  -5.27770831e+00 -1.76773871e+00 -1.59466334e-02]\n",
      " [-9.47797424e-01  8.33361112e-01 -9.06895940e-03  6.79814596e-01\n",
      "  -7.81985054e+00 -1.14487775e+00 -1.92686711e-02]\n",
      " [-7.79300104e-01  8.33361112e-01 -9.02207680e-03  5.78024175e-01\n",
      "  -2.73556609e+00  2.14540995e-01 -3.38066447e-03]\n",
      " [ 1.25319882e+00 -6.33354445e-01 -8.97499823e-03 -4.54421521e-01\n",
      "   1.26278152e+01  2.02380377e+00  3.52560790e-02]\n",
      " [ 5.05491960e-01  3.33344445e-02 -8.75836025e-03  9.81550486e-02\n",
      "  -1.94252824e+01 -4.63487644e+00 -4.81559560e-02]\n",
      " [-4.21243300e-01 -1.00003333e-01 -9.04885724e-03  3.01735890e-01\n",
      "   5.99613981e+00  1.02030556e+00  8.89643160e-03]\n",
      " [ 1.45328938e+00 -4.46681556e-01 -8.99937345e-03 -4.54421521e-01\n",
      "   1.13291121e+00 -4.25127318e-02  1.93680724e-02]\n",
      " [-1.57966237e+00  8.33361112e-01 -9.00537960e-03  4.32609288e-01\n",
      "   4.78033266e+00  2.17210400e+00  2.40622562e-02]\n",
      " [ 1.11629474e+00 -4.46681556e-01 -8.95338036e-03 -4.98045987e-01\n",
      "   1.13291121e+00  5.55631518e-01  1.93680724e-02]\n",
      " [ 6.73989279e-01 -3.13343778e-01 -9.02838303e-03 -3.81714078e-01\n",
      "   5.00138851e+00  1.06479563e+00  1.98013816e-02]\n",
      " [-8.21424434e-01  5.66685556e-01 -9.02423553e-03  4.76233754e-01\n",
      "  -4.61454078e+00 -8.08730573e-01 -5.76386547e-03]\n",
      " [ 1.26372990e-01  3.33344445e-02 -8.66576627e-03 -4.72598382e-02\n",
      "  -4.94612455e+00 -1.73313532e+00 -1.78965251e-02]\n",
      " [-8.95142012e-01  8.66695557e-02 -8.95714818e-03  3.16277379e-01\n",
      "   4.69743672e-01  5.60574859e-01  1.01241412e-02]\n",
      " [-2.66436387e+00  8.33361112e-01 -8.96575858e-03  3.16277379e-01\n",
      "   1.27383431e+01  3.66499295e+00  2.76731668e-02]\n",
      " [-1.89559485e-01  1.13337111e-01 -9.02540675e-03  1.27238026e-01\n",
      "  -1.25725512e+01 -2.57350328e+00 -2.69960198e-02]\n",
      " [-5.26554124e-02 -7.33357779e-02 -9.02735879e-03  3.99890939e-02\n",
      "  -7.48826677e+00 -1.45136489e+00 -1.11080132e-02]\n",
      " [ 1.13735691e+00 -3.66678889e-01 -8.94521702e-03 -3.52631101e-01\n",
      "  -3.95137324e+00 -8.58163982e-01  3.48006569e-03]\n",
      " [ 8.53017682e-01 -8.73362445e-01 -8.97434755e-03 -4.25338544e-01\n",
      "   2.57806380e+01  4.17415706e+00  5.69215427e-02]\n",
      " [ 2.73808145e-01 -5.80019334e-01  1.70555035e-01 -3.09006635e-01\n",
      "   1.35120386e+01  2.71587150e+00 -4.81389132e-02]]\n",
      "-----\n",
      "[[-1.11022302e-17 -1.25000000e-01  5.89969240e+00  8.32500000e+00\n",
      "   1.75750000e-01  1.81860000e+00  6.66811800e+01]]\n",
      "-----\n",
      "[[9.49570000e-01 3.74987500e+00 6.53163405e+02 6.87687500e+00\n",
      "  9.04748750e-03 2.02292340e-01 1.38469227e+03]]\n"
     ]
    }
   ],
   "source": [
    "physicochemical_properties = np.array([[0.62, -0.5, 0.007187, 8.1, 0.046, 1.181, 27.5],\n",
    "                                      [0.29, -1, -0.03661, 5.5, 0.128, 1.461, 44.6],\n",
    "                                      [-0.9, 3, -0.02382, 13, 0.105, 1.587, 40],\n",
    "                                      [-0.74, 3, 0.006802, 12.3, 0.151, 1.862, 62],\n",
    "                                      [1.19, -2.5, 0.037552, 5.2, 0.29, 2.228, 115.5],\n",
    "                                      [0.48, 0, 0.179052, 9, 0, 0.881, 0],\n",
    "                                      [-0.4, -0.5, -0.01069, 10.4, 0.23, 2.025, 79],\n",
    "                                      [1.38, -1.8, 0.021631, 5.2, 0.186, 1.81, 93.5],\n",
    "                                      [-1.5, 3, 0.017708, 11.3, 0.219, 2.258, 100],\n",
    "                                      [1.06, -1.8, 0.051672, 4.9, 0.186, 1.931, 93.5],\n",
    "                                      [0.64, -1.3, 0.002683, 5.7, 0.221, 2.034, 94.1],\n",
    "                                      [-0.78, 2, 0.005392, 11.6, 0.134, 1.655, 58.7],\n",
    "                                      [0.12, 0, 0.239531, 8, 0.131, 1.468, 41.9],\n",
    "                                      [-0.85, 0.2, 0.049211, 10.5, 0.18, 1.932, 80.7],\n",
    "                                      [-2.53, 3, 0.043587, 10.5, 0.291, 2.56, 105],\n",
    "                                      [-0.18, 0.3, 0.004627, 9.2, 0.062, 1.298, 29.3],\n",
    "                                      [-0.05, -0.4, 0.003352, 8.6, 0.108, 1.525, 51.3],\n",
    "                                      [1.08, -1.5, 0.057004, 5.9, 0.14, 1.645, 71.5],\n",
    "                                      [0.81, -3.4, 0.037977, 5.4, 0.409, 2.663, 145.5],\n",
    "                                      [0.26, -2.3, 117.3, 6.2, 0.298, 2.368, 0.023599]])\n",
    "\n",
    "mu = np.mean(physicochemical_properties, axis=0, keepdims=True)\n",
    "sig = np.var(physicochemical_properties, axis=0, keepdims=True)\n",
    "pp_normed = (physicochemical_properties - mu) / sig\n",
    "print(pp_normed)\n",
    "print(\"-----\")\n",
    "print(mu)\n",
    "print(\"-----\")\n",
    "print(sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def autocovariance(seq, pp, lag=30):\n",
    "    \"\"\"Compute and return normalized AC featurized numpy array for given sequence.\n",
    "    Dimensions are 420x1\n",
    "    \"\"\"\n",
    "    if len(seq) - lag < 1:\n",
    "        return None\n",
    "    num_pp = 7\n",
    "    aa = {'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4, 'G': 5, 'H': 6, 'I': 7, 'K': 8, 'L': 9, 'M': 10, 'N': 11, 'P': 12,\n",
    "        'Q': 13, 'R': 14, 'S': 15, 'T': 16, 'V': 17, 'W': 18, 'Y': 19}    \n",
    "    def ac_vector(seq):\n",
    "        ac = np.zeros((lag,num_pp))\n",
    "        for l in range(lag):\n",
    "            for j in range(num_pp):\n",
    "                for i in range(len(seq) - l):\n",
    "                    if not seq[i] in aa:\n",
    "                        return None\n",
    "                    if not seq[i+l] in aa:\n",
    "                        return None\n",
    "                    amino_acid_i = aa[seq[i]]\n",
    "                    amino_acid_i_l = aa[seq[i+l]]\n",
    "                    ac[l,j] += (pp[amino_acid_i, j] - pp[:,j].sum()) * (pp[amino_acid_i_l,j] - pp[:,j].sum())\n",
    "                ac[l,j] *= 1 / (len(seq) - l)\n",
    "        return ac\n",
    "    x = ac_vector(seq)\n",
    "    if x is None:\n",
    "        return x\n",
    "    return x.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save AV vectors in npy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P08521\n",
      "P0C1Z1\n",
      "P0CX86\n",
      "P0CX87\n",
      "Q3E741\n",
      "Q3E775\n",
      "Q3E7Z6\n",
      "Q3E801\n",
      "Q3E838\n",
      "Q8TGJ2\n",
      "Q8TGN3\n",
      "Q8TGS6\n",
      "Q8TGS7\n",
      "Q8TGT6\n",
      "Q8TGT8\n",
      "Q8TGU0\n",
      "Q8TGV0\n"
     ]
    }
   ],
   "source": [
    "for k,v in yeast_dset.items():\n",
    "    if os.path.exists(\"data/yeast_ac/{}.npy\".format(k)):\n",
    "        continue\n",
    "    feature_vector = autocovariance(v, pp_normed)\n",
    "    if feature_vector is None:\n",
    "        print(\"{}\".format(k))\n",
    "    np.save(\"data/yeast_ac/\" + k + \".npy\", feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k ='Q9Y6Z7'\n",
    "feature_vector = autocovariance(human_dset[k], pp_normed, lag=20)\n",
    "if feature_vector is None:\n",
    "    print(\"{}\".format(k))\n",
    "np.save(\"data/human_ac/\" + k + \".npy\", feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20127 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 20127/20127 [00:00<00:00, 1312460.26it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "for k,v in tqdm(human_dset.items()):\n",
    "    lengths.append(len(v))\n",
    "print((np.array(lengths) < 20).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20127 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 2/20127 [00:00<1:32:21,  3.63it/s]\u001b[A\n",
      "  0%|          | 3/20127 [00:00<1:42:55,  3.26it/s]\u001b[A\n",
      "  0%|          | 4/20127 [00:01<1:43:18,  3.25it/s]\u001b[A\n",
      "  0%|          | 5/20127 [00:01<1:42:13,  3.28it/s]\u001b[A\n",
      "  0%|          | 6/20127 [00:01<1:35:52,  3.50it/s]\u001b[A\n",
      "  0%|          | 7/20127 [00:02<1:44:04,  3.22it/s]\u001b[A\n",
      "  0%|          | 8/20127 [00:02<1:54:00,  2.94it/s]\u001b[A\n",
      "  0%|          | 9/20127 [00:03<1:59:23,  2.81it/s]\u001b[A\n",
      "  0%|          | 10/20127 [00:03<2:03:03,  2.72it/s]\u001b[A\n",
      "  0%|          | 11/20127 [00:03<1:55:49,  2.89it/s]Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pemami/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/pemami/anaconda3/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/pemami/anaconda3/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "100%|██████████| 20127/20127 [1:34:58<00:00,  3.53it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/human_ac/ignore.txt\", \"w+\") as f:\n",
    "    for k,v in tqdm(human_dset.items()):\n",
    "        if os.path.exists(\"data/human_ac/{}.npy\".format(k)):\n",
    "            continue\n",
    "        feature_vector = autocovariance(v, pp_normed, 20)\n",
    "        if feature_vector is None:\n",
    "            f.write(\"{}\\n\".format(k))\n",
    "        np.save(\"data/human_ac/\" + k + \".npy\", feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CLIPIGVPSLKMVCEMKKGDTLW'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for k,v in human_dset.items():\n",
    "#     print(v)\n",
    "#     break\n",
    "human_dset['M0R2V9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjoint Triad method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cluster_rep(seq):\n",
    "    aa_cluster = {\n",
    "        'A': 1,\n",
    "        'R': 5,\n",
    "        'N': 4,\n",
    "        'D': 6,\n",
    "        'C': 7,\n",
    "        'E': 6,\n",
    "        'Q': 4,\n",
    "        'G': 1,\n",
    "        'H': 4,\n",
    "        'I': 2,\n",
    "        'L': 2,\n",
    "        'K': 5,\n",
    "        'M': 3,\n",
    "        'F': 2,\n",
    "        'P': 2,\n",
    "        'S': 3,\n",
    "        'T': 3,\n",
    "        'W': 4,\n",
    "        'Y': 3,\n",
    "        'V': 1\n",
    "    }\n",
    "    new_seq = \"\"\n",
    "    for i in range(len(seq)):\n",
    "        new_seq += str(aa_cluster[seq[i]])\n",
    "    return new_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_triad(seq):\n",
    "    cluster_seq = get_cluster_rep(seq)\n",
    "    result = np.zeros((343,))\n",
    "    for i in range(len(cluster_seq)-2):\n",
    "        triad = cluster_seq[i:i+3]\n",
    "        a = int(triad[2])\n",
    "        b = int(triad[1])\n",
    "        c = int(triad[0])\n",
    "        idx = ((a-1) * 7 ** 0) + ((b-1) * 7 ** 1) + ((c-1) * 7 ** 2)\n",
    "        result[idx] += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'at'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4d969e8a159e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconvert_triad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myeast_dset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'at'"
     ]
    }
   ],
   "source": [
    "#convert_triad(yeast_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "814.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find max freq value in dataset\n",
    "max_frq = 0\n",
    "fvs = []\n",
    "for k,v in human_dset.items():\n",
    "    fv = convert_triad(v)\n",
    "    fvs.append((k,fv))\n",
    "    if np.max(fv) > max_frq:\n",
    "        max_frq = np.max(fv)\n",
    "        if max_frq == 255.0:\n",
    "            print(v)\n",
    "max_frq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxs = []\n",
    "for k,f in fvs:\n",
    "    maxs.append(np.max(f))\n",
    "maxs = np.concatenate([maxs])\n",
    "div = np.percentile(np.sort(maxs), 95)\n",
    "div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalized_fvs = []\n",
    "for k,f in fvs:\n",
    "    normalized_fvs.append((k, f / div))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "\n",
    "* [X] Save Yeast dataset using AC and CT methods\n",
    "* [ ] Do t-SNE plots of data for positive vs. negative pairs? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20128/20128 [00:00<00:00, 1330417.15it/s]\n"
     ]
    }
   ],
   "source": [
    "for k, feature_vector in tqdm(normalized_fvs):\n",
    "#for k,v in yeast_dset.items():\n",
    "    #if os.path.exists(\"data/yeast_ct/{}.npy\".format(k)):\n",
    "    #    continue\n",
    "    #feature_vector = convert_triad(v)\n",
    "    #if feature_vector is None:\n",
    "    #    print(\"{}\".format(k))\n",
    "    if k == 'Q9Y6Z7':\n",
    "        np.save(\"data/human_ct/\" + k + \".npy\", feature_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
